{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charactor-level RNN for wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    modified from https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# # Plus EOS marker\n",
    "# keywords_dict = {}\n",
    "# keywords_dict['all_letters'] = string.ascii_letters + \" .,;'-\"\n",
    "# keywords_dict['n_letters'] = len(keywords_dict['all_letters']) + 1\n",
    "\n",
    "# def findFiles(path): return glob.glob(path)\n",
    "\n",
    "# # Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "# def unicodeToAscii(s, keywords_dict):\n",
    "#     return ''.join(\n",
    "#         c for c in unicodedata.normalize('NFD', s)\n",
    "#         if unicodedata.category(c) != 'Mn'\n",
    "#         and c in keywords_dict['all_letters']\n",
    "#     )\n",
    "\n",
    "# # Read a file and split into lines\n",
    "# def readLines(filename, keywords_dict):\n",
    "#     lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "#     return [unicodeToAscii(line, keywords_dict) for line in lines]\n",
    "\n",
    "# # Build the category_lines dictionary, a list of lines per category\n",
    "# name_list = []\n",
    "# for filename in findFiles('data/names/*.txt'):\n",
    "#     category = os.path.splitext(os.path.basename(filename))[0]\n",
    "#     name_list.extend(readLines(filename, keywords_dict))\n",
    "    \n",
    "# keywords_dict['name_vector'] = name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "keywords_dict ={}\n",
    "keywords_dict['hidden_size'] = 100\n",
    "keywords_dict['seq_length'] = 25\n",
    "keywords_dict['learning_rate'] = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1000000 characters, 67 unique.\n"
     ]
    }
   ],
   "source": [
    "data = open('data/shakespeare_input.txt', 'r',encoding='utf-8').read() # should be simple plain text file\n",
    "chars = list(set(data))\n",
    "data = data[:1000000]\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "keywords_dict['data_size'] = len(data)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict['all_letters'] = ''.join(sorted(chars))\n",
    "keywords_dict['n_letters'] = len(chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.Wxh = nn.Linear(input_size, hidden_size)\n",
    "        self.Whh = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Why = nn.Linear(hidden_size, output_size)\n",
    "        self.act = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, _input, hidden):\n",
    "        # np.tanh(np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t-1]) + bh)\n",
    "        hidden = self.Wxh(_input).add(self.Whh(hidden))\n",
    "        hidden = self.act(hidden)\n",
    "        \n",
    "        output = self.Why(hidden)\n",
    "        \n",
    "        # output\n",
    "        output = self.dropout(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Random item from a list\n",
    "# def randomChoice(l):\n",
    "#     _a = l[random.randint(0, len(l) - 1)]\n",
    "#     print(_a)\n",
    "#     return _a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot matrix of first to last letters (not including EOS) for input\n",
    "def inputTensor(line, keywords_dict):\n",
    "    all_letters = keywords_dict['all_letters']\n",
    "    n_letters = keywords_dict['n_letters']\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li in range(len(line)):\n",
    "        letter = line[li]\n",
    "#         print(letter)\n",
    "        tensor[li][0][all_letters.find(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# LongTensor of second letter to end (EOS) for target\n",
    "def targetTensor(line, keywords_dict):\n",
    "    all_letters = keywords_dict['all_letters']\n",
    "    n_letters = keywords_dict['n_letters']\n",
    "    letter_indexes = [all_letters.find(line[li]) for li in range(1, len(line))]\n",
    "    letter_indexes.append(n_letters - 1) # EOS\n",
    "    return torch.LongTensor(letter_indexes)\n",
    "\n",
    "def createTrainingExample(line, keywords_dict):\n",
    "#     category, line = randomTrainingPair()\n",
    "#     line = randomChoice(keywords_dict['name_vector'])\n",
    "#     category_tensor = categoryTensor(category)\n",
    "    input_line_tensor = inputTensor(line[:-1], keywords_dict)\n",
    "#     print(input_line_tensor)\n",
    "    target_line_tensor = targetTensor(line[1:], keywords_dict)\n",
    "#     print(target_line_tensor)\n",
    "\n",
    "#     return category_tensor, input_line_tensor, target_line_tensor\n",
    "    return input_line_tensor, target_line_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # keywords_dict['learning_rate'] = 0.005\n",
    "\n",
    "# def train(rnn, keywords_dict):\n",
    "#     n, p = 0, 0\n",
    "#     while p + seq_length +1 <= len(data):\n",
    "#         input_line_tensor, target_line_tensor = createTrainingExample(data[p:p+seq_length+1], keywords_dict)\n",
    "#         print(input_line_tensor)\n",
    "#         learning_rate = keywords_dict['learning_rate']\n",
    "        \n",
    "#         target_line_tensor.unsqueeze_(-1)\n",
    "#         hidden = rnn.initHidden()\n",
    "#         rnn.zero_grad()\n",
    "#         criterion = nn.NLLLoss()\n",
    "\n",
    "#         loss = 0\n",
    "\n",
    "#         for i in range(input_line_tensor.size(0)):\n",
    "#     #         output, hidden = rnn(category_tensor, input_line_tensor[i], hidden)\n",
    "#             output, hidden = rnn(input_line_tensor[i], hidden)\n",
    "\n",
    "#             l = criterion(output, target_line_tensor[i])\n",
    "# #             print(l)\n",
    "#             loss += l\n",
    "\n",
    "#         loss.backward()\n",
    "\n",
    "#         for p in rnn.parameters():\n",
    "# #             print('Waha')\n",
    "# #             print(p)\n",
    "#             p.data.add_(-learning_rate, p.grad.data)\n",
    "#         if n % 100 == 0:\n",
    "#             print(n)\n",
    "#         p += seq_length # move data pointer\n",
    "#         n += 1 # iteration counter\n",
    "#         exit()\n",
    "#     return output, loss.item() / input_line_tensor.size(0)\n",
    "\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n",
      "torch.Size([1, 62])\n"
     ]
    }
   ],
   "source": [
    "def running(rnn, keywords_dict):\n",
    "    seq_length = keywords_dict['seq_length']\n",
    "    rnn.to(device)\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "#     n_iters = 10\n",
    "    print_every = 5000\n",
    "    plot_every = 500\n",
    "    all_losses = []\n",
    "    total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "    start = time.time()\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "    _iter, p = 0, 0\n",
    "    while p + seq_length +1 <= len(data):\n",
    "        input_line_tensor, target_line_tensor = createTrainingExample(data[p:p+seq_length+1], keywords_dict)\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "        \n",
    "        hidden = rnn.initHidden()\n",
    "        loss = 0\n",
    "#         loss.to(device)\n",
    "    \n",
    "        for i in range(input_line_tensor.size(0)):\n",
    "            output, hidden = rnn(input_line_tensor[i].to(device), hidden.to(device))\n",
    "            print(output.size())\n",
    "            l = criterion(output, target_line_tensor[i].to(device)).to(device)\n",
    "            if loss==0:\n",
    "                loss = l\n",
    "            else:\n",
    "                loss += l\n",
    "        break\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        p += seq_length # move data pointer\n",
    "        _iter += 1 # iteration counter\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        if _iter % print_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), _iter, _iter / (1000000/25) * 100, loss))\n",
    "\n",
    "        if _iter % plot_every == 0:\n",
    "            all_losses.append(total_loss / plot_every)\n",
    "            total_loss = 0\n",
    "    return rnn, all_losses\n",
    "n_letters = keywords_dict['n_letters']\n",
    "\n",
    "rnn = RNN(n_letters, 128, n_letters)\n",
    "rnn.to(device)\n",
    "rnn, all_losses = running(rnn, keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x261b635c6d8>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x261d9098278>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "% matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'hidden' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-ffefff5c8bdb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-ffefff5c8bdb>\u001b[0m in \u001b[0;36msample\u001b[1;34m(keywords_dict, start_letter)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtopi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'hidden' referenced before assignment"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "def sample(keywords_dict, start_letter='W'):\n",
    "    with torch.no_grad():  # no need to track history in sampling\n",
    "#         category_tensor = categoryTensor(category)\n",
    "        _input = inputTensor(start_letter, keywords_dict)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(max_length):\n",
    "            output, hidden = rnn(_input[0].to(device), hidden.to(device))\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            letter = keywords_dict['all_letters'][topi]\n",
    "            output_name += letter\n",
    "            _input = inputTensor(letter, keywords_dict)\n",
    "\n",
    "        return output_name\n",
    "sample(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.nn.modules.rnn.RNN"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_letter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-e288530947cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# no need to track history in sampling\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#         category_tensor = categoryTensor(category)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0m_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_letter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeywords_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_letter' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():  # no need to track history in sampling\n",
    "#         category_tensor = categoryTensor(category)\n",
    "        _input = inputTensor(start_letter, keywords_dict)\n",
    "        hidden = rnn.initHidden()\n",
    "\n",
    "        output_name = start_letter\n",
    "\n",
    "        for i in range(25):\n",
    "            output, hidden = rnn(_input[0].to(device), hidden.to(device))\n",
    "            topv, topi = output.topk(1)\n",
    "            topi = topi[0][0]\n",
    "            letter = keywords_dict['all_letters'][topi]\n",
    "            output_name += letter\n",
    "            _input = inputTensor(letter, keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000001"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sum(np.exp(np.array(output)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze_(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN3(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, n_layers, dropout=0.1)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, input):\n",
    "        hidden = self.initHidden(input.size(1))\n",
    "        return_ = []\n",
    "        for i in range(input.size(0)):\n",
    "            _input = input[i:i+1]\n",
    "            output, hidden = self.rnn(_input, hidden)\n",
    "            output = self.fc(output)\n",
    "            output = self.softmax(output)\n",
    "            return_.append(output)\n",
    "        return return_\n",
    "    \n",
    "    def prediction(self, input, hidden):\n",
    "        output, hidden = self.rnn(input, hidden)\n",
    "        output = self.fc(output)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-4.2523, -4.1594, -4.1699, -4.2205, -4.2009, -4.2164, -4.2171,\n",
       "           -4.2176, -4.2197, -4.2371, -4.2394, -4.1524, -4.1625, -4.1826,\n",
       "           -4.2385, -4.2265, -4.1625, -4.1945, -4.2177, -4.1837, -4.2111,\n",
       "           -4.1731, -4.2336, -4.1715, -4.1978, -4.1579, -4.2368, -4.2543,\n",
       "           -4.2361, -4.2385, -4.1179, -4.2428, -4.1598, -4.2166, -4.1801,\n",
       "           -4.2521, -4.2979, -4.2284, -4.1959, -4.2158, -4.1834, -4.1235,\n",
       "           -4.1715, -4.1693, -4.1514, -4.2164, -4.1780, -4.1881, -4.1893,\n",
       "           -4.2664, -4.2511, -4.1677, -4.2127, -4.2389, -4.1562, -4.1671,\n",
       "           -4.1913, -4.2419, -4.2399, -4.1979, -4.2247, -4.1891, -4.2262,\n",
       "           -4.2075, -4.2412, -4.2447, -4.2329]]], device='cuda:0'),\n",
       " tensor([[[-2.3057e-02, -2.3564e-02, -4.2954e-02,  ...,  1.4749e-02,\n",
       "            8.8703e-02, -7.4408e-02]],\n",
       " \n",
       "         [[-5.7274e-02, -6.1016e-02,  9.3120e-03,  ..., -1.4885e-03,\n",
       "           -4.8879e-02, -1.0134e-02]],\n",
       " \n",
       "         [[ 6.3342e-02,  1.7465e-02, -3.2752e-02,  ..., -5.2881e-02,\n",
       "           -7.6457e-02, -3.9089e-02]]], device='cuda:0'))"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  torch import autograd \n",
    "\n",
    "input_line_tensor, target_line_tensor = createTrainingExample(data[0:26], keywords_dict)\n",
    "rnn_ = RNN3(keywords_dict['n_letters'], 512, keywords_dict['n_letters'], 3)\n",
    "if torch.cuda.is_available:\n",
    "    rnn_.cuda()\n",
    "# _ = input_line_tensor.long()\n",
    "output = rnn_(input_line_tensor.cuda())\n",
    "# output = rnn_(input_line_tensor.cuda())\n",
    "# # input_line_tensor[0:1]\n",
    "rnn_.prediction(input_line_tensor[0:1].cuda(), rnn_.initHidden(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 40s (500 1%) 77.6373\n",
      "1m 20s (1000 2%) 84.1484\n",
      "2m 1s (1500 3%) 86.6846\n",
      "2m 41s (2000 5%) 121.4769\n",
      "3m 21s (2500 6%) 88.7474\n",
      "4m 2s (3000 7%) 75.2751\n",
      "4m 42s (3500 8%) 92.3100\n",
      "5m 23s (4000 10%) 85.6432\n",
      "6m 3s (4500 11%) 79.6013\n",
      "6m 44s (5000 12%) 74.3576\n",
      "7m 24s (5500 13%) 87.5127\n",
      "8m 4s (6000 15%) 76.2123\n",
      "8m 45s (6500 16%) 90.3462\n",
      "9m 25s (7000 17%) 79.5136\n",
      "10m 6s (7500 18%) 92.2264\n",
      "10m 47s (8000 20%) 97.5097\n",
      "11m 28s (8500 21%) 86.2393\n",
      "12m 9s (9000 22%) 82.4376\n",
      "12m 50s (9500 23%) 102.5323\n",
      "13m 33s (10000 25%) 84.1528\n",
      "14m 16s (10500 26%) 101.1602\n",
      "14m 58s (11000 27%) 80.3856\n",
      "15m 39s (11500 28%) 93.1155\n",
      "16m 23s (12000 30%) 91.7584\n",
      "17m 3s (12500 31%) 87.9460\n",
      "17m 44s (13000 32%) 78.6555\n",
      "18m 24s (13500 33%) 85.0535\n",
      "19m 4s (14000 35%) 81.6005\n",
      "19m 45s (14500 36%) 78.9428\n",
      "20m 25s (15000 37%) 84.9486\n",
      "21m 6s (15500 38%) 82.1121\n",
      "21m 46s (16000 40%) 82.4816\n",
      "22m 26s (16500 41%) 120.9892\n",
      "23m 7s (17000 42%) 92.3614\n",
      "23m 47s (17500 43%) 86.7239\n",
      "24m 27s (18000 45%) 92.6668\n",
      "25m 8s (18500 46%) 82.6646\n",
      "25m 48s (19000 47%) 90.6038\n",
      "26m 28s (19500 48%) 83.0181\n",
      "27m 9s (20000 50%) 81.9022\n",
      "27m 49s (20500 51%) 89.2414\n",
      "28m 29s (21000 52%) 83.6284\n",
      "29m 10s (21500 53%) 84.0809\n",
      "29m 50s (22000 55%) 79.2025\n",
      "30m 31s (22500 56%) 79.4038\n",
      "31m 12s (23000 57%) 88.9420\n",
      "31m 53s (23500 58%) 137.6964\n",
      "32m 33s (24000 60%) 81.0523\n",
      "33m 14s (24500 61%) 85.1214\n",
      "33m 54s (25000 62%) 78.1418\n",
      "34m 35s (25500 63%) 80.4823\n",
      "35m 15s (26000 65%) 79.6569\n",
      "35m 56s (26500 66%) 84.4910\n",
      "36m 36s (27000 67%) 90.8955\n",
      "37m 17s (27500 68%) 84.3341\n",
      "37m 57s (28000 70%) 82.6783\n",
      "38m 38s (28500 71%) 101.6387\n",
      "39m 18s (29000 72%) 81.8188\n",
      "39m 59s (29500 73%) 87.8913\n",
      "40m 39s (30000 75%) 99.0213\n",
      "41m 20s (30500 76%) 85.1102\n",
      "42m 1s (31000 77%) 77.0870\n",
      "42m 41s (31500 78%) 81.2588\n",
      "43m 21s (32000 80%) 125.7258\n",
      "44m 2s (32500 81%) 87.7070\n",
      "44m 42s (33000 82%) 92.9841\n",
      "45m 22s (33500 83%) 77.9342\n",
      "46m 3s (34000 85%) 94.2421\n",
      "46m 43s (34500 86%) 82.7241\n",
      "47m 23s (35000 87%) 76.5304\n",
      "48m 4s (35500 88%) 78.7469\n",
      "48m 44s (36000 90%) 86.5721\n",
      "49m 24s (36500 91%) 80.0519\n",
      "50m 5s (37000 92%) 80.9092\n",
      "50m 45s (37500 93%) 78.0768\n",
      "51m 25s (38000 95%) 83.8417\n",
      "52m 5s (38500 96%) 74.2389\n",
      "52m 46s (39000 97%) 73.7285\n",
      "53m 26s (39500 98%) 75.7250\n"
     ]
    }
   ],
   "source": [
    "def running(keywords_dict):\n",
    "    n_letters = keywords_dict['n_letters']\n",
    "    rnn =  RNN3(n_letters, 512, n_letters, 3)\n",
    "    rnn.to(device)    \n",
    "\n",
    "\n",
    "    seq_length = keywords_dict['seq_length']\n",
    "    optimizer = torch.optim.Adam(rnn.parameters(), lr=0.001)\n",
    "#     n_iters = 10\n",
    "    print_every = 5000\n",
    "    plot_every = 500\n",
    "    all_losses = []\n",
    "    total_loss = 0 # Reset every plot_every iters\n",
    "\n",
    "    start = time.time()\n",
    "    criterion = nn.NLLLoss().to(device)\n",
    "    \n",
    "    _iter, p = 0, 0\n",
    "    while p + seq_length +1 <= keywords_dict['data_size']:\n",
    "        input_line_tensor, target_line_tensor = createTrainingExample(data[p:p+seq_length+1], keywords_dict)\n",
    "#         print(input_line_tensor.size())\n",
    "        target_line_tensor.unsqueeze_(-1)\n",
    "\n",
    "        input_line_tensor = input_line_tensor.cuda()\n",
    "        output = rnn(input_line_tensor)\n",
    "#         print(output)\n",
    "        loss = 0\n",
    "        for i in range(input_line_tensor.size(0)):\n",
    "            l = criterion(output[i][0], target_line_tensor[i].to(device))\n",
    "#             print(l)\n",
    "            if loss==0:\n",
    "                loss = l\n",
    "            else:\n",
    "                loss += l\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        p += seq_length # move data pointer\n",
    "        _iter += 1 # iteration counter\n",
    "\n",
    "        total_loss += loss\n",
    "\n",
    "        if _iter % plot_every == 0:\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start), _iter, _iter / (keywords_dict['data_size']/keywords_dict['seq_length']) * 100, loss))\n",
    "\n",
    "        if _iter % plot_every == 0:\n",
    "            all_losses.append(total_loss / plot_every)\n",
    "            total_loss = 0\n",
    "    return rnn, all_losses\n",
    "n_letters = keywords_dict['n_letters']\n",
    "\n",
    "# rnn = nn.RNN(input_size=n_letters, hidden_size=512, num_layers=3, nonlinearity='tanh')\n",
    "# rnn.to(device)\n",
    "rnn, all_losses = running( keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 5\n",
    "\n",
    "# Sample from a category and starting letter\n",
    "# def sample(keywords_dict, start_letter='A'):\n",
    "with torch.no_grad():  # no need to track history in sampling\n",
    "#         category_tensor = categoryTensor(category)\n",
    "    start_letter='C'\n",
    "    _input = inputTensor(start_letter, keywords_dict)\n",
    "#         _input.to(device)\n",
    "    hidden = rnn.initHidden(1)\n",
    "    output_name = start_letter\n",
    "\n",
    "    for i in range(max_length):\n",
    "        output, hidden = rnn.prediction(_input.to(device), hidden.to(device))\n",
    "        topv, topi = output[0][0].topk(1)\n",
    "        topi = topi[0]\n",
    "        letter = keywords_dict['all_letters'][topi]\n",
    "        output_name += letter\n",
    "        _input = inputTensor(letter, keywords_dict)\n",
    "        _input.to(device)\n",
    "#     return output_name\n",
    "# sample(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "        topv, topi = output[0][0].topk(1)\n",
    "#         topi = topi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict['all_letters'][topi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOE\\n\\n '"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
